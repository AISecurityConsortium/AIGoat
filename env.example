# Red Team Shop - Environment Configuration
# This file contains all configurable environment variables used by the application
# Copy this file to .env and update the values as needed

# =============================================================================
# BACKEND CONFIGURATION (Django)
# =============================================================================

# Django Security Settings
SECRET_KEY=django-insecure-ezr0q%1q61hl92z5=_5g0ef!-afexujpshdbey3kyp*ud
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1

# AI Service Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral

# LLM Parameters
OLLAMA_TEMPERATURE=0.7          # Creativity level (0.0-1.0, higher = more creative)
OLLAMA_TOP_P=0.9               # Nucleus sampling (0.0-1.0, higher = more diverse)
OLLAMA_TOP_K=40                # Top-k sampling (1-100, higher = more diverse)
OLLAMA_NUM_PREDICT=500         # Maximum tokens to generate
OLLAMA_MAX_INPUT_LENGTH=1000   # Maximum input length for validation
OLLAMA_TIMEOUT=60              # Request timeout in seconds

# =============================================================================
# FRONTEND CONFIGURATION (React)
# =============================================================================

# API Configuration
REACT_APP_API_URL=http://localhost:8000

# =============================================================================
# DEPLOYMENT NOTES
# =============================================================================
# 
# For production deployment:
# 1. Set SECRET_KEY to a secure random string
# 2. Set DEBUG=False
# 3. Update ALLOWED_HOSTS with your domain/IP
# 4. Update OLLAMA_BASE_URL to your Ollama service URL
# 5. Update REACT_APP_API_URL to your backend API URL
#
# Example production values:
# SECRET_KEY=your-super-secret-key-here
# DEBUG=False
# ALLOWED_HOSTS=your-domain.com,your-ip-address
# OLLAMA_BASE_URL=https://your-ollama-service.com
# OLLAMA_MODEL=llama2  # or mistral, codellama, etc.
# OLLAMA_TEMPERATURE=0.3  # Lower for more consistent responses
# OLLAMA_TOP_P=0.8        # Adjust for response diversity
# OLLAMA_TOP_K=20         # Lower for faster generation
# OLLAMA_NUM_PREDICT=300  # Adjust based on model capabilities
# OLLAMA_MAX_INPUT_LENGTH=2000  # Increase for longer inputs
# OLLAMA_TIMEOUT=120      # Increase for slower models
# REACT_APP_API_URL=https://your-backend-api.com
